{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "from functools import partial\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared_home/smuckati/miniconda3/envs/relora_sft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the length of the labels\n",
    "tasks = ['cola', 'sst2', 'mrpc', 'qqp', 'mnli', 'qnli', 'rte', 'wnli']\n",
    "tasks_to_labels = {\n",
    "    'cola': ['unacceptable', 'acceptable'],\n",
    "    'sst2': ['negative', 'positive'],\n",
    "    'mrpc': ['not_equivalent', 'equivalent'],\n",
    "    'qqp': ['not_duplicate', 'duplicate'],\n",
    "    # processed differently as this is a regression task\n",
    "    'sts-b': [],\n",
    "    'mnli': ['entailment', 'neutral', 'contradiction'],\n",
    "    'qnli': ['entailment', 'not_entailment'],\n",
    "    'rte': ['entailment', 'not_entailment'],\n",
    "    'wnli': ['not_entailment', 'entailment']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The task is cola\n",
      "unacceptable\n",
      "[29452, 1]\n",
      "Tokenized length is 2\n",
      "acceptable\n",
      "[9961, 1]\n",
      "Tokenized length is 2\n",
      "The task is sst2\n",
      "negative\n",
      "[2841, 1]\n",
      "Tokenized length is 2\n",
      "positive\n",
      "[1465, 1]\n",
      "Tokenized length is 2\n",
      "The task is mrpc\n",
      "not_equivalent\n",
      "[59, 834, 15, 1169, 15592, 1]\n",
      "Tokenized length is 6\n",
      "equivalent\n",
      "[7072, 1]\n",
      "Tokenized length is 2\n",
      "The task is qqp\n",
      "not_duplicate\n",
      "[59, 834, 26, 413, 26221, 1]\n",
      "Tokenized length is 6\n",
      "duplicate\n",
      "[19197, 1]\n",
      "Tokenized length is 2\n",
      "The task is mnli\n",
      "entailment\n",
      "[3, 35, 5756, 297, 1]\n",
      "Tokenized length is 5\n",
      "neutral\n",
      "[7163, 1]\n",
      "Tokenized length is 2\n",
      "contradiction\n",
      "[27252, 1]\n",
      "Tokenized length is 2\n",
      "The task is qnli\n",
      "entailment\n",
      "[3, 35, 5756, 297, 1]\n",
      "Tokenized length is 5\n",
      "not_entailment\n",
      "[59, 834, 35, 5756, 297, 1]\n",
      "Tokenized length is 6\n",
      "The task is rte\n",
      "entailment\n",
      "[3, 35, 5756, 297, 1]\n",
      "Tokenized length is 5\n",
      "not_entailment\n",
      "[59, 834, 35, 5756, 297, 1]\n",
      "Tokenized length is 6\n",
      "The task is wnli\n",
      "not_entailment\n",
      "[59, 834, 35, 5756, 297, 1]\n",
      "Tokenized length is 6\n",
      "entailment\n",
      "[3, 35, 5756, 297, 1]\n",
      "Tokenized length is 5\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"glue\"\n",
    "for task in tasks:\n",
    "    print(f\"The task is {task}\")\n",
    "    dataset = load_dataset(dataset_name, task)\n",
    "    labels = tasks_to_labels[task]\n",
    "    for label in labels:\n",
    "        print(label)\n",
    "        label_tokens = tokenizer(label)\n",
    "        print(label_tokens[\"input_ids\"])\n",
    "        input_ids = label_tokens[\"input_ids\"]\n",
    "        print(f\"Tokenized length is {len(input_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glue(x, benchmark_name, label_names, feature_names=None, id_key='idx'):\n",
    "    \"\"\"Convert a dataset from glue to text2text examples.\n",
    "\n",
    "    This function uses the feature names from the dataset to unpack examples into\n",
    "    a format amenable for a text2text problem. For example, consider the Quora\n",
    "    Question Pairs (QQP) benchmark, which would suggest\n",
    "    benchmark_name=\"qqp\"\n",
    "    label_names=['not_duplicate', 'duplicate']\n",
    "    For QQP, a typical example might look like\n",
    "    {\n",
    "        \"question1\": \"Why do I easily get bored of my friends?\",\n",
    "        \"question2\": \"Why do I get bored of friends so quickly?\",\n",
    "        \"label\": 1,\n",
    "        \"idx\": 10,\n",
    "    }\n",
    "\n",
    "    This example would be transformed to\n",
    "    {\n",
    "        \"inputs\": (\n",
    "            \"qqp question1: Why do I easily get bored of my friends? question2: \"\n",
    "            \"Why do I get bored of my friends so quickly?\"\n",
    "        ),\n",
    "        \"targets\": \"duplicate\",\n",
    "        \"idx\": 10,\n",
    "    }\n",
    "\n",
    "    Args:\n",
    "        x: an example to process.\n",
    "        benchmark_name: the name of the GLUE benchmark for this dataset.\n",
    "        label_names: a list of label names corresponding to class index.\n",
    "        feature_names: an optional ordered list of feature names. If provided,\n",
    "        features will be ordered in this way in the output. If not provided, all\n",
    "        features (except 'idx' and 'label') will be used, sorted by name.\n",
    "        id_key: str, key for id in the dataset. If not provided, 'idx' will be used.\n",
    "        if None, no id will be added to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        A preprocessed example.\n",
    "    \"\"\"\n",
    "    feature_keys = feature_names or sorted(set(x.keys()).difference(['label', 'idx']))\n",
    "    strs_to_join = []\n",
    "    for key in feature_keys:\n",
    "        strs_to_join.append('{}:'.format(key))\n",
    "        strs_to_join.append(x[key])\n",
    "    strs_to_join.insert(0, benchmark_name)\n",
    "    label_name = '<unk>' if x['label'] == -1 else label_names[x['label']]\n",
    "    joined = ' '.join(strs_to_join)\n",
    "\n",
    "    ex = {}\n",
    "    ex['inputs'] = joined\n",
    "    ex['targets'] = label_name\n",
    "\n",
    "    return ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_decoder(examples):\n",
    "        # add a separator between inputs and targets for the model to learn when to predict the targets\n",
    "        inputs = examples['inputs'] + \":\" + examples['targets']\n",
    "        inputs = tokenizer(inputs, return_tensors='pt')\n",
    "\n",
    "        return {'input_ids': len(inputs['input_ids'].squeeze(0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The task is cola\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8551/8551 [00:01<00:00, 4907.11 examples/s]\n",
      "Map: 100%|██████████| 1043/1043 [00:00<00:00, 4577.90 examples/s]\n",
      "Map: 100%|██████████| 1063/1063 [00:00<00:00, 4579.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for cola is: 54\n",
      "The task is sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 67349/67349 [00:13<00:00, 4867.59 examples/s]\n",
      "Map: 100%|██████████| 872/872 [00:00<00:00, 4103.17 examples/s]\n",
      "Map: 100%|██████████| 1821/1821 [00:00<00:00, 4154.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for sst2 is: 93\n",
      "The task is mrpc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3668/3668 [00:01<00:00, 2923.72 examples/s]\n",
      "Map: 100%|██████████| 408/408 [00:00<00:00, 2859.91 examples/s]\n",
      "Map: 100%|██████████| 1725/1725 [00:00<00:00, 2821.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for mrpc is: 147\n",
      "The task is qqp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 363846/363846 [01:37<00:00, 3732.94 examples/s]\n",
      "Map: 100%|██████████| 40430/40430 [00:11<00:00, 3526.55 examples/s]\n",
      "Map: 100%|██████████| 390965/390965 [01:42<00:00, 3815.68 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for qqp is: 361\n",
      "The task is mnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  43%|████▎     | 170095/392702 [00:50<01:05, 3401.53 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 392702/392702 [01:56<00:00, 3367.38 examples/s]\n",
      "Map: 100%|██████████| 9815/9815 [00:03<00:00, 3132.22 examples/s]\n",
      "Map: 100%|██████████| 9832/9832 [00:02<00:00, 3340.66 examples/s]\n",
      "Map: 100%|██████████| 9796/9796 [00:02<00:00, 3455.32 examples/s]\n",
      "Map: 100%|██████████| 9847/9847 [00:02<00:00, 3390.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for mnli is: 542\n",
      "The task is qnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 104743/104743 [00:34<00:00, 3013.47 examples/s]\n",
      "Map: 100%|██████████| 5463/5463 [00:02<00:00, 2460.94 examples/s]\n",
      "Map: 100%|██████████| 5463/5463 [00:01<00:00, 2805.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for qnli is: 669\n",
      "The task is rte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2490/2490 [00:01<00:00, 2457.76 examples/s]\n",
      "Map: 100%|██████████| 277/277 [00:00<00:00, 2251.95 examples/s]\n",
      "Map: 100%|██████████| 3000/3000 [00:01<00:00, 2622.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for rte is: 323\n",
      "The task is wnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 635/635 [00:00<00:00, 2996.65 examples/s]\n",
      "Map: 100%|██████████| 71/71 [00:00<00:00, 2806.14 examples/s]\n",
      "Map: 100%|██████████| 146/146 [00:00<00:00, 2849.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length inputs for wnli is: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(f\"The task is {task}\")\n",
    "    dataset = load_dataset(dataset_name, task)  \n",
    "    glue_partial = partial(glue, benchmark_name=task, label_names=tasks_to_labels[task])\n",
    "    column_names = dataset['train'].column_names\n",
    "    dataset = dataset.map(glue_partial, remove_columns=column_names)\n",
    "    old_columns = dataset['train'].column_names\n",
    "    tokenized_dataset = dataset.map(preprocess_function_decoder, remove_columns=old_columns)\n",
    "    len_ids = max([tokenized_dataset[\"train\"][token_ids][\"input_ids\"] for token_ids in range(0, len(tokenized_dataset[\"train\"]))])\n",
    "    print(f\"The maximum length inputs for {task} is: {len_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated string is ['prediction</s><pad><pad><pad>not_entailment<pad><pad>']\n",
      "Label index is 1\n"
     ]
    }
   ],
   "source": [
    "output_text = \"prediction</s><pad><pad><pad>not_entailment<pad><pad>\"\n",
    "decoded_labels = \"not_entailment\"\n",
    "\n",
    "generated_strings = output_text.strip().lower().split(\" \")\n",
    "print(f\"Generated string is {generated_strings}\")\n",
    "\n",
    "#decoded_labels = tokenizer.decode(labels[idx], skip_special_tokens=True)\n",
    "label_index = -1\n",
    "# you will always have one decoded_label even for strings like not_entailment\n",
    "if decoded_labels in output_text:\n",
    "    label_index = tasks_to_labels[\"rte\"].index(decoded_labels)\n",
    "    print(f\"Label index is {label_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prompts from flan templates \n",
    "# https://github.com/google-research/FLAN/blob/main/flan/templates.py\n",
    "import templates\n",
    "from preprocessors import glue, stsb, string_to_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for task cola is ('Sentence: \"{sentence}\"\\nWould a linguist rate this sentence to be acceptable linguistically?\\n\\n{options_}', '{answer}')\n",
      "The prompt for task sst2 is ('Review:\\n{sentence}\\nIs this movie review sentence negative or positive?\\n{options_}', '{answer}')\n",
      "The prompt for task glue_mrpc is ('Here are two sentences:\\n{sentence1}\\n{sentence2}\\nDo they have the same meaning?\\n{options_}', '{answer}')\n",
      "The prompt for task glue_qqp is ('{question1}\\n{question2}\\nWould you say that these questions are the same?\\n{options_}', '{answer}')\n",
      "The prompt for task mnli is ('Premise: {premise}\\n\\nHypothesis: {hypothesis}\\n\\nDoes the premise entail the hypothesis?\\n\\n{options_}', '{answer}')\n",
      "The prompt for task qnli is ('Does the sentence \"{sentence}\" answer the question \"{question}\"\\n\\n{options_}', '{answer}')\n",
      "The prompt for task rte is ('{premise}\\n\\nBased on the paragraph above can we conclude that \"{hypothesis}\"?\\n\\n{options_}', '{answer}')\n",
      "The prompt for task wnli is ('If \"{sentence1}\", can we conclude that \"{sentence2}\"\\n{options_}', '{answer}')\n"
     ]
    }
   ],
   "source": [
    "tasks = ['cola', 'sst2', 'glue_mrpc', 'glue_qqp', 'mnli', 'qnli', 'rte', 'wnli']\n",
    "for task in tasks:\n",
    "    # pick the first prompt in the flan template\n",
    "    prompt = templates.PATTERNS[task][0]\n",
    "    print(f\"The prompt for task {task} is {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\"),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\"),\n",
    "    \"sts-b\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'soulful and ', 'label': 1, 'idx': 60108}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric, DatasetDict\n",
    "benchmark_name = 'sst2'\n",
    "dataset = load_dataset('glue', benchmark_name)\n",
    "smaller_dataset = DatasetDict()\n",
    "for split in dataset.keys():\n",
    "    subset_size = 10\n",
    "    smaller_dataset[split] = dataset[split].shuffle(seed=42).select(range(subset_size))\n",
    "dataset = smaller_dataset\n",
    "\n",
    "data = smaller_dataset['train'][2]\n",
    "print(f'{data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n",
      "sentence\n",
      "('sentence',)\n",
      "The number of labels are: 2\n",
      "Prompt is Review:\n",
      "{sentence}\n",
      "Is this movie review sentence negative or positive?\n",
      "{options_}\n",
      "Template filled is Review:\n",
      "soulful and \n",
      "Is this movie review sentence negative or positive?\n",
      "A) negative\n",
      "B) positive\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_names = tasks_to_labels[benchmark_name]\n",
    "print(label_names)\n",
    "feature_keys = task_to_keys[benchmark_name]\n",
    "print(feature_keys)\n",
    "\n",
    "if benchmark_name == 'rte':\n",
    "    premise = data['sentence1']\n",
    "    hypothesis = data['sentence2']\n",
    "else:\n",
    "    # create variables with the same name as the strings - will need it to fill in the template\n",
    "    variables = task_to_keys.get(benchmark_name, ())\n",
    "    variables = (variables,) if isinstance(variables, str) else variables\n",
    "    print(variables)\n",
    "    locals().update({var: data[var] for var in variables})\n",
    "\n",
    "    if 'premise' not in locals():\n",
    "        premise = ''\n",
    "    if 'hypothesis' not in locals():\n",
    "        hypothesis = ''\n",
    "\n",
    "# find out how many labels are there\n",
    "num_labels = len(tasks_to_labels[benchmark_name])\n",
    "print(f\"The number of labels are: {num_labels}\")\n",
    "if num_labels == 3:\n",
    "    options_ = f'A) {label_names[0]}\\nB){label_names[1]}\\nC){label_names[2]}' # You can modify the options as needed\n",
    "    if data['label'] == 0:\n",
    "        answer = 'A'\n",
    "    elif data['label'] == 1:\n",
    "        answer = 'B'\n",
    "    elif data['label'] == 2:\n",
    "        answer = 'C'\n",
    "elif num_labels == 2:\n",
    "    options_ = f'A) {label_names[0]}\\nB) {label_names[1]}' # You can modify the options as needed\n",
    "    answer = 'A' if data['label'] == 0 else 'B' # Modify according to the label mapping\n",
    "prompt_template = templates.PATTERNS[benchmark_name][0][0] # extract first prompt and since its a tuple extract string\n",
    "print(f'Prompt is {prompt_template}')\n",
    "filled_prompt = prompt_template.format(\n",
    "    premise=premise,\n",
    "    hypothesis=hypothesis,\n",
    "    sentence=locals().get('sentence', ''),\n",
    "    sentence1=locals().get('sentence1', ''),\n",
    "    sentence2=locals().get('sentence2', ''),\n",
    "    question=locals().get('question', ''),\n",
    "    question1=locals().get('question1', ''),\n",
    "    question2=locals().get('question2', ''),\n",
    "    options_=options_,\n",
    ")\n",
    "\n",
    "template_filled = (filled_prompt, answer)\n",
    "new_temp = filled_prompt + '\\n' + answer\n",
    "\n",
    "print(f'Template filled is {new_temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared_home/smuckati/miniconda3/envs/relora_sft/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", use_fast=True)\n",
    "dataset = load_dataset('glue', 'sst2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(dataset['train'][0]['sentence']).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    length = len(tokenizer(examples['sentence']).input_ids)\n",
    "    return {'lengths': length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=8): 100%|██████████| 67349/67349 [00:01<00:00, 43542.49 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 872/872 [00:00<00:00, 5504.87 examples/s]\n",
      "Map (num_proc=8): 100%|██████████| 1821/1821 [00:00<00:00, 9673.77 examples/s] \n"
     ]
    }
   ],
   "source": [
    "new_dataset = dataset.map(\n",
    "                    preprocess,\n",
    "                    num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = new_dataset['train'][:]['lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([num for num in len_list if num > 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(len_list, binrange=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1_key, sentence2_key = ('sentence', None)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    texts = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    ) \n",
    "    result = tokenizer(*texts, padding=False, max_length=512, truncation=True)\n",
    "\n",
    "    # if \"label\" in examples:\n",
    "    #     if label_to_id is not None:\n",
    "    #         # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    #         result[\"labels\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "    #     else:\n",
    "    #         # In all cases, rename the column to labels because the model will expect that.\n",
    "    #         result[\"labels\"] = examples[\"label\"]\n",
    "    \n",
    "    #get the length of the tokenized inputs\n",
    "    result['lengths'] = len(result['input_ids'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:   0%|          | 0/872 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 872/872 [00:00<00:00, 4958.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=False,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'lengths'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'lengths'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'lengths'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2579, 150, 3, 7820, 3, 6, 163, 5347, 15, 26, 23856, 7, 1],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'lengths': 13}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60\n",
    "def filter_by_length(example):\n",
    "    return example['lengths'] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = processed_datasets['train'].filter(filter_by_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13, 392, 75, 63, 1],\n",
       " 'attention_mask': [1, 1, 1, 1, 1],\n",
       " 'lengths': 5}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13, 392, 75, 63, 1],\n",
       " 'attention_mask': [1, 1, 1, 1, 1],\n",
       " 'lengths': 5}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_datasets['train'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relora_sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
